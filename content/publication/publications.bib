%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Shamsuddeen Muhammad at 2020-11-07 05:10:34 +0000 


%% Saved with string encoding Unicode (UTF-8) 



@article{Inuwa-Dutse:2018aa,
	Abstract = {In recent years, social bots have been using increasingly more sophisticated, challenging detection strategies. While many approaches and features have been proposed, social bots evade detection and interact much like humans making it difficult to distinguish real human accounts from bot accounts. For detection systems, various features under the broader categories of account profile, tweet content, network and temporal pattern have been utilised. The use of tweet content features is limited to analysis of basic terms such as URLs, hashtags, name entities and sentiment. Given a set of tweet contents with no obvious pattern can we distinguish contents produced by social bots from that of humans? We aim to answer this question by analysing the lexical richness of tweets produced by the respective accounts using large collections of different datasets. Our results show a clear margin between the two classes in lexical diversity, lexical sophistication and distribution of emoticons. We found that the proposed lexical features significantly improve the performance of classifying both account types. These features are useful for training a standard machine learning classifier for effective detection of social bot accounts. A new dataset is made freely available for further exploration.},
	Author = {Isa Inuwa-Dutse and Bello Shehu Bello and Ioannis Korkontzelos},
	Date-Added = {2020-11-07 05:10:23 +0000},
	Date-Modified = {2020-11-07 05:10:23 +0000},
	Eprint = {1812.07947},
	Journal = {Dutse, I.I, Bello, B. S., &},
	Pages = {I.},
	Title = {Lexical analysis of automated accounts on Twitter},
	Url = {https://arxiv.org/pdf/1812.07947.pdf},
	Volume = {Korkontzelos},
	Year = {2018},
	Bdsk-Url-1 = {https://arxiv.org/pdf/1812.07947.pdf},
	Bdsk-Url-2 = {https://arxiv.org/abs/1812.07947}}

@article{Nekoto:2020aa,
	Abstract = {Research in NLP lacks geographic diversity, and the question of how NLP can be scaled to low-resourced languages has not yet been adequately solved. "Low-resourced"-ness is a complex problem going beyond data availability and reflects systemic problems in society. In this paper, we focus on the task of Machine Translation (MT), that plays a crucial role for information accessibility and communication worldwide. Despite immense improvements in MT over the past decade, MT is centered around a few high-resourced languages. As MT researchers cannot solve the problem of low-resourcedness alone, we propose participatory research as a means to involve all necessary agents required in the MT development process. We demonstrate the feasibility and scalability of participatory research with a case study on MT for African languages. Its implementation leads to a collection of novel translation datasets, MT benchmarks for over 30 languages, with human evaluations for a third of them, and enables participants without formal training to make a unique scientific contribution. Benchmarks, models, data, code, and evaluation results are released under https://github.com/masakhane-io/masakhane-mt.},
	Author = {Wilhelmina Nekoto and Vukosi Marivate and Tshinondiwa Matsila and Timi Fasubaa and Tajudeen Kolawole and Taiwo Fagbohungbe and Solomon Oluwole Akinola and Shamsuddee Hassan Muhammad and Salomon Kabongo and Salomey Osei and Sackey Freshia and Rubungo Andre Niyongabo and Ricky Macharm and Perez Ogayo and Orevaoghene Ahia and Musie Meressa and Mofe Adeyemi and Masabata Mokgesi-Selinga and Lawrence Okegbemi and Laura Jane Martinus and Kolawole Tajudeen and Kevin Degila and Kelechi Ogueji and Kathleen Siminyu and Julia Kreutzer},
	Date-Added = {2020-11-07 05:07:50 +0000},
	Date-Modified = {2020-11-07 05:07:50 +0000},
	Eprint = {2010.02353},
	Month = {10},
	Title = {Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages},
	Url = {https://arxiv.org/pdf/2010.02353.pdf},
	Year = {2020},
	Bdsk-Url-1 = {https://arxiv.org/pdf/2010.02353.pdf},
	Bdsk-Url-2 = {https://arxiv.org/abs/2010.02353}}

@article{Abdulmumin:2020aa,
	Abstract = {Improving neural machine translation (NMT) models using the back-translations of the monolingual target data (synthetic parallel data) is currently the state-of-the-art approach for training improved translation systems. The quality of the backward system - which is trained on the available parallel data and used for the back-translation - has been shown in many studies to affect the performance of the final NMT model. In low resource conditions, the available parallel data is usually not enough to train a backward model that can produce the qualitative synthetic data needed to train a standard translation model. This work proposes a self-training strategy where the output of the backward model is used to improve the model itself through the forward translation technique. The technique was shown to improve baseline low resource IWSLT'14 English-German and IWSLT'15 English-Vietnamese backward translation models by 11.06 and 1.5 BLEUs respectively. The synthetic data generated by the improved English-German backward model was used to train a forward model which out-performed another forward model trained using standard back-translation by 2.7 BLEU.},
	Author = {Idris Abdulmumin and Bashir Shehu Galadanci and Abubakar Isa},
	Date-Added = {2020-11-07 05:02:01 +0000},
	Date-Modified = {2020-11-07 05:02:01 +0000},
	Eprint = {2006.02876},
	Month = {06},
	Title = {Using Self-Training to Improve Back-Translation in Low Resource Neural Machine Translation},
	Url = {https://arxiv.org/pdf/2006.02876.pdf},
	Year = {2020},
	Bdsk-Url-1 = {https://arxiv.org/pdf/2006.02876.pdf},
	Bdsk-Url-2 = {https://arxiv.org/abs/2006.02876}}

@article{Abdulmumin:2019ab,
	Abstract = {An effective method to generate a large number of parallel sentences for training improved neural machine translation (NMT) systems is the use of back-translations of the target-side monolingual data. The method was not able to utilize the available huge amount of monolingual data because of the inability of models to differentiate between the authentic and synthetic parallel data. Tagging, or using gates, has been used to enable translation models to distinguish between synthetic and authentic data, improving standard back-translation and also enabling the use of iterative back-translation on language pairs that under-performed using standard back-translation. This work presents pre-training and fine-tuning as a simplified but more effective approach of differentiating between the two data. The approach - tag-less back-translation - trains the model on the synthetic data and fine-tunes it on the authentic data. Experiments have shown the approach to outperform the baseline and standard back-translation by 4.0 and 0.7 BLEU respectively on low resource English-Vietnamese NMT. While the need for tagging (noising) the dataset has been removed, the technique outperformed tagged back-translation by 0.4 BLEU. The approach reached the best scores in less training time than the standard and tagged back-translation approaches.},
	Author = {Idris Abdulmumin and Bashir Shehu Galadanci and Aliyu Garba},
	Date-Added = {2020-11-07 05:01:08 +0000},
	Date-Modified = {2020-11-07 05:01:08 +0000},
	Eprint = {1912.10514},
	Month = {12},
	Title = {Tag-less Back-Translation},
	Url = {https://arxiv.org/pdf/1912.10514.pdf},
	Year = {2019},
	Bdsk-Url-1 = {https://arxiv.org/pdf/1912.10514.pdf},
	Bdsk-Url-2 = {https://arxiv.org/abs/1912.10514}}

@article{Abdulmumin:2019aa,
	Abstract = {Words embedding (distributed word vector representations) have become an essential component of many natural language processing (NLP) tasks such as machine translation, sentiment analysis, word analogy, named entity recognition and word similarity. Despite this, the only work that provides word vectors for Hausa language is that of Bojanowski et al. [1] trained using fastText, consisting of only a few words vectors. This work presents words embedding models using Word2Vec's Continuous Bag of Words (CBoW) and Skip Gram (SG) models. The models, hauWE (Hausa Words Embedding), are bigger and better than the only previous model, making them more useful in NLP tasks. To compare the models, they were used to predict the 10 most similar words to 30 randomly selected Hausa words. hauWE CBoW's 88.7% and hauWE SG's 79.3% prediction accuracy greatly outperformed Bojanowski et al. [1]'s 22.3%.},
	Author = {Idris Abdulmumin and Bashir Shehu Galadanci},
	Date-Added = {2020-11-07 05:00:32 +0000},
	Date-Modified = {2020-11-07 05:00:32 +0000},
	Doi = {10.1109/NigeriaComputConf45974.2019.8949674},
	Eprint = {1911.10708},
	Month = {11},
	Title = {hauWE: Hausa Words Embedding for Natural Language Processing},
	Url = {https://arxiv.org/pdf/1911.10708.pdf},
	Year = {2019},
	Bdsk-Url-1 = {https://arxiv.org/pdf/1911.10708.pdf},
	Bdsk-Url-2 = {https://arxiv.org/abs/1911.10708},
	Bdsk-Url-3 = {https://doi.org/10.1109/NigeriaComputConf45974.2019.8949674}}

@article{ahmad2019review,
	Author = {Ahmad, Ibrahim Said and Bakar, Azuraliza Abu and Yaakub, Mohd Ridzwan},
	Journal = {International Journal of Advanced Computer Research},
	Number = {44},
	Pages = {283--292},
	Publisher = {International Journal of Advanced Computer Research},
	Title = {A review of feature selection in sentiment analysis using information gain and domain specific ontology},
	Volume = {9},
	Year = {2019}}

@article{ahmad2020survey,
	Author = {Ahmad, Ibrahim Said and Bakar, Azuraliza Abu and Yaakub, Mohd Ridzwan and Muhammad, Shamsuddeen Hassan},
	Journal = {SN Computer Science},
	Number = {4},
	Pages = {1--14},
	Publisher = {Springer},
	Title = {A survey on machine learning techniques in movie revenue prediction},
	Volume = {1},
	Year = {2020}}

@article{ahmadbeyond,
	Author = {Ahmad, Ibrahim Said and Bakar, Azuraliza Abu and Yaakub, Mohd Ridzwan and Darwich, Mohammad},
	Date-Modified = {2020-11-06 15:50:30 +0000},
	Journal = {International Journal of Advanced Computer Science and Applications(IJACSA)},
	Title = {Beyond Sentiment Classification: A Novel Approach for Utilizing Social Media Data for Business Intelligence},
	Volume = {3},
	Year = {2020}}

@article{osman2019current,
	Author = {OSMAN, AIDA and AHMAD, SAID},
	Journal = {Journal of Theoretical and Applied Information Technology},
	Number = {22},
	Title = {CURRENT TRENDS AND RESEARCH DIRECTIONS IN THE DICTIONARY-BASED APPROACH FOR SENTIMENT LEXICON GENERATION: A SURVEY},
	Volume = {97},
	Year = {2019}}

@article{ahmad2020sequel,
	Author = {Ahmad, Ibrahim Said and Bakar, Azuraliza Abu and Yaakub, Mohd Ridzwan and Darwich, Mohammad},
	Journal = {Data Technologies and Applications},
	Publisher = {Emerald Publishing Limited},
	Title = {Sequel movie revenue prediction model based on sentiment analysis},
	Year = {2020}}

@article{ahmad2020movie,
	Author = {Ahmad, Ibrahim Said and Bakar, Azuraliza Abu and Yaakub, Mohd Ridzwan},
	Journal = {Information Processing \& Management},
	Number = {5},
	Pages = {102278},
	Publisher = {Elsevier},
	Title = {Movie Revenue Prediction Based on Purchase Intention Mining Using YouTube Trailer Reviews},
	Volume = {57},
	Year = {2020}}

@inproceedings{muhammad2019overview,
	Author = {Muhammad, Shamsuddeen Hassan},
	Booktitle = {MAP-i Seminar Proceedings},
	Pages = {65--70},
	Title = {An overview of sentiment analysis approaches},
	Year = {2019}}

@inproceedings{muhammad2020incremental,
	Author = {Muhammad, Shamsuddeen Hassan and Brazdil, Pavel and Jorge, Al{\'\i}pio},
	Booktitle = {European Conference on Information Retrieval},
	Organization = {Springer},
	Pages = {619--623},
	Title = {Incremental Approach for Automatic Generation of Domain-Specific Sentiment Lexicon},
	Year = {2020}}

@inproceedings{bello2018reverse,
	Author = {Bello, Bello Shehu and Heckel, Reiko and Minku, Leandro},
	Booktitle = {2018 Fifth International Conference on Social Networks Analysis, Management and Security (SNAMS)},
	Organization = {IEEE},
	Pages = {27--34},
	Title = {Reverse engineering the behaviour of twitter bots},
	Year = {2018}}

@article{inuwa2018effect,
	Author = {Inuwa-Dutsea, Isa and Bello, Bello Shehu and Korkontzelos, Ioannis and Reiko, Heckel},
	Journal = {IADIS International Journal on WWW/Internet},
	Number = {2},
	Title = {The effect of engagement intensity and lexical richness in identifying bot accounts on twitter},
	Volume = {16},
	Year = {2018}}

@inproceedings{bello2019analyzing,
	Author = {Bello, Bello Shehu and Heckel, Reiko},
	Booktitle = {2019 Sixth International Conference on Social Networks Analysis, Management and Security (SNAMS)},
	Organization = {IEEE},
	Pages = {61--66},
	Title = {Analyzing the Behaviour of Twitter Bots in Post Brexit Politics},
	Year = {2019}}
